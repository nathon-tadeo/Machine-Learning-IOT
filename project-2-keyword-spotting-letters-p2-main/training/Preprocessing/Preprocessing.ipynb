{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXPPoeE4V78g"
      },
      "source": [
        "Rewrite all recorded files into PCM format so they can be read properly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAQbRhSPwUnS",
        "outputId": "4acd1e69-0f2a-49a5-b405-54e69bd94b4f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "from scipy.io import wavfile\n",
        "\n",
        "# Define the directory containing the .wav files\n",
        "input_directory = \"/content/drive/My Drive/ML_IOT/dataset/watermelon\"\n",
        "output_directory = \"/content/drive/My Drive/ML_IOT/dataset/watermelonnew\"\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "# Get a list of all .wav files in the directory\n",
        "filenames = [file for file in os.listdir(input_directory) if file.endswith(\".wav\")]\n",
        "\n",
        "# Define the desired length (16000 samples)\n",
        "desired_length = 16000\n",
        "\n",
        "# Define the target sample rate\n",
        "target_sample_rate = 16000\n",
        "\n",
        "# Loop through each file in the directory\n",
        "for filename in filenames:\n",
        "    # Read the audio data\n",
        "    selected_filename = os.path.join(input_directory, filename)\n",
        "    audio_data, fs = librosa.load(selected_filename, sr=None)\n",
        "\n",
        "    # Resample the audio to the target sample rate\n",
        "    audio_data_resampled = librosa.resample(audio_data, orig_sr=fs, target_sr=target_sample_rate)\n",
        "\n",
        "    # Trim or pad the audio to the desired length\n",
        "    current_length = len(audio_data_resampled)\n",
        "    if current_length < desired_length:\n",
        "        # If the current length is less, zero-pad the audio signal\n",
        "        padded_audio_data = np.pad(audio_data_resampled, (0, desired_length - current_length), 'constant')\n",
        "    elif current_length > desired_length:\n",
        "        # If the current length is greater, trim the audio signal\n",
        "        padded_audio_data = audio_data_resampled[:desired_length]\n",
        "    else:\n",
        "        # If the current length is equal, no adjustment is needed\n",
        "        padded_audio_data = audio_data_resampled\n",
        "\n",
        "    # Convert audio data to 16-bit PCM format\n",
        "    pcm_audio_data = (padded_audio_data * 32767).astype(np.int16)\n",
        "\n",
        "    # Save the PCM audio to the output directory\n",
        "    output_filename = os.path.join(output_directory, filename)\n",
        "    wavfile.write(output_filename, target_sample_rate, pcm_audio_data)\n",
        "\n",
        "    print(f\"Processed: {filename}\")\n",
        "\n",
        "print(\"All files processed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzYporf-WHkW"
      },
      "source": [
        "Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAgk_Mytk-ZF",
        "outputId": "9239d669-266f-4731-cdbc-f562f0a468a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'libasound2-dev' instead of 'libasound-dev'\n",
            "libasound2-dev is already the newest version (1.2.6.1-1ubuntu1).\n",
            "libportaudio2 is already the newest version (19.6.0-1.1).\n",
            "libportaudiocpp0 is already the newest version (19.6.0-1.1).\n",
            "portaudio19-dev is already the newest version (19.6.0-1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Requirement already satisfied: pyaudio in /usr/local/lib/python3.10/dist-packages (0.2.14)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ],
      "source": [
        "!apt install libasound-dev portaudio19-dev libportaudio2 libportaudiocpp0\n",
        "!pip install pyaudio\n",
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdcpV6dMlBo7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.lite.experimental.microfrontend.python.ops import audio_microfrontend_op as frontend_op\n",
        "import numpy as np\n",
        "import time\n",
        "from scipy.io import wavfile\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "import os\n",
        "import pathlib\n",
        "import glob\n",
        "from datetime import datetime as dt\n",
        "from numpy import log as ln\n",
        "import matplotlib.mlab as mlab\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io.wavfile import write\n",
        "import IPython\n",
        "import IPython.display as ipd\n",
        "import tensorflow as tf\n",
        "%matplotlib inline\n",
        "import pyaudio\n",
        "from queue import Queue\n",
        "from threading import Thread\n",
        "import math\n",
        "import time\n",
        "import librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTb9_DEVlDoO",
        "outputId": "99640678-6e0a-4a21-de46-e8f4c7d94da9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvIJNyIMlV28"
      },
      "outputs": [],
      "source": [
        "# Helper libraries\n",
        "from IPython import display as ipd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import wavfile\n",
        "import librosa.util\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "\n",
        "data_dir = '/content/drive/My Drive/ML_IOT/dataset/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5vkqSxwWf1m"
      },
      "source": [
        "Make directories to store new files in if not already done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TubKlmnElXZ7",
        "outputId": "8121dfec-766c-483a-e446-9e46c3af1350"
      },
      "outputs": [],
      "source": [
        "# Set the word you want to augment\n",
        "custom_word = 'watermelon'\n",
        "\n",
        "# Check if the directory for the raw audio files of the custom word already exists\n",
        "if os.path.exists(os.path.join(data_dir, (custom_word))):\n",
        "    # If it does, print an error message\n",
        "    print(f'Error: The directory {os.path.join(data_dir, (custom_word))} already exists.')\n",
        "    raw_audio_dir = os.path.join(data_dir, (custom_word))\n",
        "\n",
        "else:\n",
        "    print(f'Creating the directory {os.path.join(data_dir, (custom_word))}')\n",
        "    # Set the path for the raw audio files\n",
        "    raw_audio_dir = os.path.join(data_dir, (custom_word))\n",
        "    # Create the directory\n",
        "    os.makedirs(raw_audio_dir)\n",
        "\n",
        "# Check if the directory for the augmented audio files of the custom word already exists\n",
        "if os.path.exists(os.path.join(data_dir,(custom_word + 'new'))):\n",
        "    # If it does, print an error message\n",
        "    print(f'Error: The directory {os.path.join(data_dir, (custom_word +\"new\"))} already exists.')\n",
        "    aug_audio_dir = os.path.join(data_dir, (custom_word))\n",
        "\n",
        "else:\n",
        "    print(f'Creating the directory {os.path.join(data_dir, (custom_word + \"new\"))}')\n",
        "    # Set the path for the augmented audio files\n",
        "    aug_audio_dir = os.path.join(data_dir, (custom_word + 'new'))\n",
        "    # Create the directory\n",
        "    os.makedirs(aug_audio_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF1jNk3rWnpy"
      },
      "source": [
        "Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezeG9g4llZYZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import librosa\n",
        "from scipy.io import wavfile\n",
        "\n",
        "raw_audio_dir = '/content/drive/My Drive/ML_IOT/watermelon_pcm'\n",
        "aug_audio_dir = '/content/drive/My Drive/ML_IOT/dataset/watermelonnew'\n",
        "\n",
        "# Ensure the output directory exists\n",
        "os.makedirs(aug_audio_dir, exist_ok=True)\n",
        "\n",
        "# Get a list of all .wav files in the raw data directory\n",
        "filenames = glob.glob(os.path.join(raw_audio_dir, '*.wav'))\n",
        "\n",
        "# Counter for augmented files\n",
        "augmented_count = 0\n",
        "\n",
        "# Define the target number of augmentations per original file\n",
        "target_augmentations = 50\n",
        "\n",
        "for wav_file in filenames:\n",
        "    # Load the audio file\n",
        "    fs, wav = wavfile.read(wav_file)\n",
        "\n",
        "    # Normalize the audio data\n",
        "    wav = wav / np.max(np.abs(wav))\n",
        "\n",
        "    # Apply augmentations until reaching the target number\n",
        "    while augmented_count < target_augmentations:\n",
        "        # Apply time stretching to the audio (rate>1 => faster/shorter)\n",
        "        wav_long = librosa.effects.time_stretch(wav, rate=np.random.uniform(0.5, 0.8))\n",
        "        # Apply time stretching to the audio (rate<1 => slower/longer)\n",
        "        wav_short = librosa.effects.time_stretch(wav, rate=np.random.uniform(1.2, 1.5))\n",
        "        # Apply pitch shifting to the audio (n_steps>0 => higher pitch)\n",
        "        wav_up = librosa.effects.pitch_shift(wav, sr=fs, n_steps=np.random.randint(3, 8), bins_per_octave=12)\n",
        "        # Apply pitch shifting to the audio (n_steps<0 => lower pitch)\n",
        "        wav_dn = librosa.effects.pitch_shift(wav, sr=fs, n_steps=np.random.randint(-6, -2), bins_per_octave=12)\n",
        "        # Trim the silent parts of the audio\n",
        "        wav_trim, _ = librosa.effects.trim(wav, top_db=40)\n",
        "\n",
        "        # Get the base filename (without the directory)\n",
        "        base_filename = os.path.basename(wav_file)\n",
        "\n",
        "        # Save the augmented audio files to the new data directory\n",
        "        wavfile.write(os.path.join(aug_audio_dir, os.path.splitext(base_filename)[0] + f'_{augmented_count}_long.wav'), fs, wav_long)\n",
        "        wavfile.write(os.path.join(aug_audio_dir, os.path.splitext(base_filename)[0] + f'_{augmented_count}_short.wav'), fs, wav_short)\n",
        "        wavfile.write(os.path.join(aug_audio_dir, os.path.splitext(base_filename)[0] + f'_{augmented_count}_up.wav'), fs, wav_up)\n",
        "        wavfile.write(os.path.join(aug_audio_dir, os.path.splitext(base_filename)[0] + f'_{augmented_count}_down.wav'), fs, wav_dn)\n",
        "        wavfile.write(os.path.join(aug_audio_dir, os.path.splitext(base_filename)[0] + f'_{augmented_count}_trim.wav'), fs, wav_trim)\n",
        "\n",
        "        # Increment the augmented count\n",
        "        augmented_count += 1\n",
        "\n",
        "    # Reset the augmented count for the next original file\n",
        "    augmented_count = 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXEC3HNhWzgH"
      },
      "source": [
        "Play audio from the original recorded files to make sure they imported correctly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "TQahLaV0lbqi",
        "outputId": "377d0ba8-39d5-4e43-c15c-23c06a814adb"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/My Drive/ML_IOT/watermelon_pcm'\n",
        "filenames = [os.path.join(data_dir, file) for file in os.listdir(data_dir) if file.endswith(\".wav\")]\n",
        "\n",
        "# Testing if audio data imported correctly\n",
        "test_wav = filenames[0]\n",
        "fs, test_wav_data = wavfile.read(test_wav)\n",
        "\n",
        "# Plotting the audio signal\n",
        "plt.plot(np.arange(len(test_wav_data))/fs, test_wav_data)\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.title('Audio Signal')\n",
        "plt.show()\n",
        "\n",
        "# Playing the audio\n",
        "ipd.Audio(test_wav_data, rate=fs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jV4G-MrldFA",
        "outputId": "3ad13ab4-99b8-4302-d645-fe50900551b7"
      },
      "outputs": [],
      "source": [
        "!pip install librosa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IXJdDitW9_K"
      },
      "source": [
        "View info about the newly created files in the augmented directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFDQ2XQdlgUY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "data_dir = '/content/drive/My Drive/ML_IOT/dataset/watermelonnew'\n",
        "\n",
        "# List all files in the directory\n",
        "files = os.listdir(data_dir)\n",
        "\n",
        "# Count the number of files\n",
        "num_files = len(files)\n",
        "\n",
        "print(f\"Number of files in {data_dir}: {num_files}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJtHB4cCXDNw"
      },
      "source": [
        "Make sure the data augmented properly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCXXvr9-lluD"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Selecting augmentation folder & files ******\n",
        "filenames = [os.path.join(data_dir, file) for file in os.listdir(data_dir) if file.endswith(\".wav\")]\n",
        "\n",
        "# Testing if audio data imported correctly\n",
        "test_wav = filenames[1]\n",
        "fs, test_wav_data = wavfile.read(test_wav)\n",
        "\n",
        "# Plotting the audio signal\n",
        "plt.plot(np.arange(len(test_wav_data))/fs, test_wav_data)\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.title('Audio Signal')\n",
        "plt.show()\n",
        "\n",
        "# Playing the audio\n",
        "ipd.Audio(test_wav_data, rate=fs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ycmLkzaXVTw"
      },
      "source": [
        "Verify that all the original and augmented files exist in the proper location in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Si27JA4rlmNY"
      },
      "outputs": [],
      "source": [
        "# Set the directory path containing the WAV files\n",
        "data_dir = '/content/drive/My Drive/ML_IOT/dataset'\n",
        "filenames = tf.io.gfile.glob(str(data_dir) + '/*/*.wav')\n",
        "#Verifying opens files correctly\n",
        "filenames[0]\n",
        "\n",
        "num_files=len(filenames)\n",
        "num_files\n",
        "print(\"Total files:\", num_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqdA_BerYJX6"
      },
      "source": [
        "Create the testing list .txt file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlr8Q0DFlnwu",
        "outputId": "2dfd122c-ede5-48b8-8b47-b5867a7bedee"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Set directory for testing list\n",
        "dir_path = Path('/content/drive/My Drive/ML_IOT/dataset/')  # Assuming you want to save files in the '/content' directory\n",
        "\n",
        "file_name = '/content/drive/My Drive/ML_IOT/dataset/testing_list.txt'\n",
        "\n",
        "# How many files to add to document?\n",
        "add_val_num = 2000\n",
        "\n",
        "# List of keywords\n",
        "keywords = ['watermelon', 'yes']\n",
        "\n",
        "# Check if directory exists\n",
        "if dir_path.is_dir():\n",
        "    # Check if the file exists, if not, create it\n",
        "    if not (dir_path / file_name).is_file():\n",
        "        with open(dir_path / file_name, 'w') as f:\n",
        "            f.write('')\n",
        "            print(\"Created empty file:\", file_name)\n",
        "\n",
        "    # Open the file in append mode\n",
        "    with open(dir_path / file_name, 'a') as f:\n",
        "        for keyword in keywords:\n",
        "            # Get the list of files for this keyword\n",
        "            keyword_files = tf.io.gfile.glob(f'/content/drive/My Drive/ML_IOT/dataset/{keyword}/*.wav')\n",
        "            # Generate a random list for this keyword\n",
        "            keyword_random_list = list(range(0, len(keyword_files)))\n",
        "            random.shuffle(keyword_random_list)\n",
        "            # Add the selected files to the validation list\n",
        "            for i in range(min(add_val_num, len(keyword_files))):\n",
        "              if keyword_files:  # Check if keyword_files is not empty\n",
        "                  f.write('\\n' + keyword + '/' + os.path.basename(keyword_files[keyword_random_list[i]]))\n",
        "              else:\n",
        "                  print(f\"No files found for keyword: {keyword}\")\n",
        "    print(add_val_num * len(keywords), \"samples added to\", file_name)\n",
        "else:\n",
        "    print('Directory does not exist')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZdsUPIQYMuN"
      },
      "source": [
        "Create the validation list .txt file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmPTMXWPvRT-",
        "outputId": "96d4f392-5c24-4f12-b2b3-8563cef0f1a2"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Set directory for validation list\n",
        "dir_path = Path('/content/drive/My Drive/ML_IOT/dataset/')  # Assuming you want to save files in the '/content' directory\n",
        "\n",
        "file_name = '/content/drive/My Drive/ML_IOT/dataset/validation_list.txt'\n",
        "\n",
        "# How many files to add to document?\n",
        "add_val_num = 800\n",
        "\n",
        "# List of keywords\n",
        "keywords = ['watermelon', 'yes']\n",
        "\n",
        "# Check if directory exists\n",
        "if dir_path.is_dir():\n",
        "    # Check if the file exists, if not, create it\n",
        "    if not (dir_path / file_name).is_file():\n",
        "        with open(dir_path / file_name, 'w') as f:\n",
        "            f.write('')\n",
        "            print(\"Created empty file:\", file_name)\n",
        "\n",
        "    # Open the file in append mode\n",
        "    with open(dir_path / file_name, 'a') as f:\n",
        "        for keyword in keywords:\n",
        "            # Get the list of files for this keyword\n",
        "            keyword_files = tf.io.gfile.glob(f'/content/drive/My Drive/ML_IOT/dataset/{keyword}/*.wav')\n",
        "            # Generate a random list for this keyword\n",
        "            keyword_random_list = list(range(0, len(keyword_files)))\n",
        "            random.shuffle(keyword_random_list)\n",
        "            # Add the selected files to the validation list\n",
        "            for i in range(min(add_val_num, len(keyword_files))):\n",
        "              if keyword_files:  # Check if keyword_files is not empty\n",
        "                  f.write('\\n' + keyword + '/' + os.path.basename(keyword_files[keyword_random_list[i]]))\n",
        "              else:\n",
        "                  print(f\"No files found for keyword: {keyword}\")\n",
        "    print(add_val_num * len(keywords), \"samples added to\", file_name)\n",
        "else:\n",
        "    print('Directory does not exist')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
