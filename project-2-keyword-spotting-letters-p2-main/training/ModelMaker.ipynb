{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrpFKPJbdqfq"
      },
      "source": [
        "Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfyyNLh3CmoP",
        "outputId": "f43c7f29-ec7f-43cd-c6d1-1807cc868681"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.lite.experimental.microfrontend.python.ops import audio_microfrontend_op as frontend_op\n",
        "print(tf.__version__)\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "# from tqdm import tqdm # replace with this if moving out of notebook\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import pathlib\n",
        "\n",
        "from datetime import datetime as dt\n",
        "\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjIZwxiTd8T5"
      },
      "source": [
        "Initialize necessary values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5vY-QTFdCsFM"
      },
      "outputs": [],
      "source": [
        "# Set seed for experiment reproducibility\n",
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLIUS5DfCtsB"
      },
      "outputs": [],
      "source": [
        "i16min = -2**15 # Min value for 16 bit integer\n",
        "i16max = 2**15-1 # Max value for 16 bit integer\n",
        "fsamp = 16000 # Frequency (in Hz)\n",
        "wave_length_ms = 1000\n",
        "wave_length_samps = int(wave_length_ms*fsamp/1000)\n",
        "window_size_ms=60\n",
        "window_step_ms=40\n",
        "num_filters = 32\n",
        "use_microfrontend = True\n",
        "dataset = 'full-speech-files' # use the full speech commands stored as files\n",
        "\n",
        "silence_str = \"_silence\"\n",
        "unknown_str = \"_unknown\"\n",
        "EPOCHS = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gudqe_neCvDa",
        "outputId": "24996f7c-ab0a-4bc8-8f7e-4486a27e2565"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERDtmo-ECz9W"
      },
      "source": [
        "Create the labels list and make sure the .wav files imported correctly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y69v1GJNCx5u"
      },
      "outputs": [],
      "source": [
        "commands = ['yes', 'watermelon']\n",
        "if dataset == 'full-speech-files':\n",
        "  data_dir = pathlib.Path(os.path.join('/content/drive/My Drive/ML_IOT/dataset/'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gJHiCfIC3f9",
        "outputId": "6da90f58-5c74-4466-df80-bc7a40a55e9f"
      },
      "outputs": [],
      "source": [
        "data_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmZlgyz9C41h",
        "outputId": "61046286-ffb5-49dd-d3c9-a5670f526ab6"
      },
      "outputs": [],
      "source": [
        "# Create label list\n",
        "label_list = commands.copy()\n",
        "label_list.insert(0, silence_str)\n",
        "label_list.insert(1, unknown_str)\n",
        "print('label_list:', label_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJAEiEEtC6G5",
        "outputId": "42fe2f89-e580-40cc-972c-650012852dde"
      },
      "outputs": [],
      "source": [
        "# Make sure files imported correctly\n",
        "if dataset == 'mini-speech' or dataset == 'full-speech-files':\n",
        "    filenames = tf.io.gfile.glob(str(data_dir) + '/*/*.wav')\n",
        "    filenames = tf.random.shuffle(filenames)\n",
        "    num_samples = len(filenames)\n",
        "    print('Number of total examples:', num_samples)\n",
        "    print('Example file tensor:', filenames[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zfkk6iwOfjKD"
      },
      "source": [
        "Read the files from the validation and testing list files. Create the training list from the remaining files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsvmD03lC79d",
        "outputId": "d90a8a00-d8da-4825-c9a6-e1c1be84a49e"
      },
      "outputs": [],
      "source": [
        "if dataset == 'full-speech-files':\n",
        "  fname_val_files = os.path.join(data_dir, 'validation_list.txt')\n",
        "  with open(fname_val_files) as fpi_val:\n",
        "    val_files = fpi_val.read().splitlines()\n",
        "  val_files = [os.path.join(data_dir, fn) for fn in val_files]\n",
        "  # Check if the specific file path exists in val_files and remove it if it does\n",
        "  if '/content/drive/My Drive/ML_IOT/dataset/' in val_files:\n",
        "      val_files.remove('/content/drive/My Drive/ML_IOT/dataset/')\n",
        "  for line in val_files[:5]:\n",
        "      print(line)\n",
        "\n",
        "  fname_test_files = os.path.join(data_dir, 'testing_list.txt')\n",
        "  with open(fname_test_files) as fpi_tst:\n",
        "      test_files = fpi_tst.read().splitlines()\n",
        "  test_files = [os.path.join(data_dir, fn.strip()) for fn in test_files]  # Use strip() instead of rstrip()\n",
        "  # Check if the specific file path exists in val_files and remove it if it does\n",
        "  if '/content/drive/My Drive/ML_IOT/dataset/' in test_files:\n",
        "      test_files.remove('/content/drive/My Drive/ML_IOT/dataset/')\n",
        "  for line in test_files[:5]:\n",
        "      print(line)\n",
        "\n",
        "\n",
        "  # convert the TF tensor filenames into an array of strings so we can use basic python constructs\n",
        "  train_files = [f.decode('utf8') for f in filenames.numpy()]\n",
        "  # don't train with the _background_noise_ files; exclude when directory name starts with '_'\n",
        "  train_files = [f for f in train_files if f.split('/')[-2][0] != '_']\n",
        "  # validation and test files are listed explicitly in *_list.txt; train with everything else\n",
        "  train_files = list(set(train_files) - set(test_files) - set(val_files))\n",
        "  # now convert back into a TF tensor so we can use the tf.dataset pipeline\n",
        "  train_files = tf.constant(train_files)\n",
        "print('Training set size', len(train_files))\n",
        "print('Validation set size', len(val_files))\n",
        "print('Test set size', len(test_files))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNx1VJtSf-Yt"
      },
      "source": [
        "Define functions to unpack the audio files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FXvVSZ28C9dA"
      },
      "outputs": [],
      "source": [
        "def decode_audio(audio_binary):\n",
        "  audio, _ = tf.audio.decode_wav(audio_binary)\n",
        "  return tf.squeeze(audio, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1cbEEwfCC-xb"
      },
      "outputs": [],
      "source": [
        "def get_label(file_path):\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  in_set = tf.reduce_any(parts[-2] == label_list)\n",
        "  label = tf.cond(in_set, lambda: parts[-2], lambda: tf.constant(unknown_str))\n",
        "  return  label # parts[-2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YiCRMZ_zDAGY"
      },
      "outputs": [],
      "source": [
        "def get_waveform_and_label(file_path):\n",
        "  label = get_label(file_path)\n",
        "  audio_binary = tf.io.read_file(file_path)\n",
        "  waveform = decode_audio(audio_binary)\n",
        "  return waveform, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ukzGQuYpDBoS"
      },
      "outputs": [],
      "source": [
        "def get_spectrogram(waveform):\n",
        "  zero_padding = tf.zeros([wave_length_samps] - tf.shape(waveform), dtype=tf.int16)\n",
        "  waveform = tf.cast(0.5*waveform*(i16max-i16min), tf.int16)  # scale float [-1,+1]=>INT16\n",
        "  equal_length = tf.concat([waveform, zero_padding], 0)\n",
        "  spectrogram = frontend_op.audio_microfrontend(equal_length, sample_rate=fsamp, num_channels=num_filters,\n",
        "                                    window_size=window_size_ms, window_step=window_step_ms)\n",
        "  return spectrogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6bCjRWHDF6F"
      },
      "source": [
        "Create waveforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6cwD2r-1DDhj"
      },
      "outputs": [],
      "source": [
        "def create_silence_dataset(num_waves, samples_per_wave, rms_noise_range=[0.01,0.2], silent_label=silence_str):\n",
        "    # create num_waves waveforms of white gaussian noise, with rms level drawn from rms_noise_range\n",
        "    # to act as the \"silence\" dataset\n",
        "    rng = np.random.default_rng()\n",
        "    rms_noise_levels = rng.uniform(low=rms_noise_range[0], high=rms_noise_range[1], size=num_waves)\n",
        "    rand_waves = np.zeros((num_waves, samples_per_wave), dtype=np.float32) # pre-allocate memory\n",
        "    for i in range(num_waves):\n",
        "        rand_waves[i,:] = rms_noise_levels[i]*rng.standard_normal(samples_per_wave)\n",
        "    labels = [silent_label]*num_waves\n",
        "    return tf.data.Dataset.from_tensor_slices((rand_waves, labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "T-SDe6IFDKYA"
      },
      "outputs": [],
      "source": [
        "def wavds2specds(waveform_ds, verbose=True):\n",
        "  wav, label = next(waveform_ds.as_numpy_iterator())\n",
        "  one_spec = get_spectrogram(wav)\n",
        "  one_spec = tf.expand_dims(one_spec, axis=0)  # add a 'batch' dimension at the front\n",
        "  one_spec = tf.expand_dims(one_spec, axis=-1) # add a singleton 'channel' dimension at the back\n",
        "\n",
        "  num_waves = 0 # count the waveforms so we can allocate the memory\n",
        "  for wav, label in waveform_ds:\n",
        "    num_waves += 1\n",
        "  print(f\"About to create spectrograms from {num_waves} waves\")\n",
        "  spec_shape = (num_waves,) + one_spec.shape[1:]\n",
        "  spec_grams = np.nan * np.zeros(spec_shape)  # allocate memory\n",
        "  labels = np.nan * np.zeros(num_waves)\n",
        "  idx = 0\n",
        "  for wav, label in waveform_ds:\n",
        "    if verbose and idx % 250 == 0:\n",
        "      print(f\"\\r {idx} wavs processed\", end='')\n",
        "    spectrogram = get_spectrogram(wav)\n",
        "    # TF conv layer expect inputs structured as 4D (batch_size, height, width, channels)\n",
        "    # the microfrontend returns 2D tensors (freq, time), so we need to\n",
        "    spectrogram = tf.expand_dims(spectrogram, axis=0)  # add a 'batch' dimension at the front\n",
        "    spectrogram = tf.expand_dims(spectrogram, axis=-1) # add a singleton 'channel' dimension at the back\n",
        "    spec_grams[idx, ...] = spectrogram\n",
        "    new_label = label.numpy().decode('utf8')\n",
        "    new_label_id = np.argmax(new_label == np.array(label_list))\n",
        "    labels[idx] = new_label_id # for numeric labels\n",
        "    # labels.append(new_label) # for string labels\n",
        "    idx += 1\n",
        "  labels = np.array(labels, dtype=int)\n",
        "  output_ds = tf.data.Dataset.from_tensor_slices((spec_grams, labels))\n",
        "  return output_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lydZvXGrDLl3",
        "outputId": "7d4e4ab1-38fe-4cc2-df37-786c4a218e9c"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "num_train_files = len(train_files)\n",
        "files_ds = tf.data.Dataset.from_tensor_slices(train_files)\n",
        "waveform_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\n",
        "train_ds = wavds2specds(waveform_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n1rOoJ6gOsO"
      },
      "source": [
        "Plot waveforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0NngFRwcDNNY",
        "outputId": "0671e8c2-3d13-4fe2-9948-20a53be7d892"
      },
      "outputs": [],
      "source": [
        "rows = 3\n",
        "cols = 3\n",
        "n = rows*cols\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(10, 12))\n",
        "for i, (audio, label) in enumerate(waveform_ds.take(n)):\n",
        "  r = i // cols\n",
        "  c = i % cols\n",
        "  ax = axes[r][c]\n",
        "  ax.plot(audio.numpy())\n",
        "  ax.set_yticks(np.arange(-1.2, 1.2, 0.2))\n",
        "  label = label.numpy().decode('utf-8')\n",
        "  ax.set_title(label)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s_K2WQegY2w"
      },
      "source": [
        "Functions for preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MERsfiN_DOzc"
      },
      "outputs": [],
      "source": [
        "# Adds noise to waveforms\n",
        "def copy_with_noise(ds_input, rms_level=0.25):\n",
        "  rng = tf.random.Generator.from_seed(1234)\n",
        "  wave_shape = tf.constant((wave_length_samps,))\n",
        "  def add_noise(waveform, label):\n",
        "    noise = rms_level*rng.normal(shape=wave_shape)\n",
        "    zero_padding = tf.zeros([wave_length_samps] - tf.shape(waveform), dtype=tf.float32)\n",
        "    waveform = tf.concat([waveform, zero_padding], 0)\n",
        "    noisy_wave = waveform + noise\n",
        "    return noisy_wave, label\n",
        "\n",
        "  return ds_input.map(add_noise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAz3stojDQWj",
        "outputId": "b3b5737d-1439-4f63-a87c-09eda090ce98"
      },
      "outputs": [],
      "source": [
        "# waveform_ds = augment_with_noise(waveform_ds)\n",
        "count = 0\n",
        "for w,l in waveform_ds:\n",
        "  if w.shape != (16000,):\n",
        "    print(f\"element {count} has shape {w.shape}\")\n",
        "    break\n",
        "  count += 1\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_uYLc25zDRtK"
      },
      "outputs": [],
      "source": [
        "# Pads a waveform with 0s to ensure it has 16000 samples\n",
        "def pad_16000(waveform, label):\n",
        "    zero_padding = tf.zeros([wave_length_samps] - tf.shape(waveform), dtype=tf.float32)\n",
        "    waveform = tf.concat([waveform, zero_padding], 0)\n",
        "    return waveform, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iAZJ2BvNDTLD"
      },
      "outputs": [],
      "source": [
        "def count_labels(dataset):\n",
        "    counts = {}\n",
        "    for _, lbl in dataset:\n",
        "        if lbl.dtype == tf.string:\n",
        "            label = lbl.numpy().decode('utf-8')\n",
        "        else:\n",
        "            label = lbl.numpy()\n",
        "        if label in counts:\n",
        "            counts[label] += 1\n",
        "        else:\n",
        "            counts[label] = 1\n",
        "    return counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yqI_c3fPDUtk"
      },
      "outputs": [],
      "source": [
        "# Collect what we did to generate the training dataset into a\n",
        "# function, so we can repeat with the validation and test sets.\n",
        "def preprocess_dataset(files, num_silent=None, noisy_reps_of_known=None):\n",
        "  # if noisy_reps_of_known is not None, it should be a list of rms noise levels\n",
        "  # For every target word in the data set, 1 copy will be created with each level\n",
        "  # of noise added to it.  So [0.1, 0.2] will add 2x noisy copies of the target words\n",
        "  if num_silent is None:\n",
        "    num_silent = int(0.2*len(files))+1\n",
        "  print(f\"Processing {len(files)} files\")\n",
        "  files_ds = tf.data.Dataset.from_tensor_slices(files)\n",
        "  waveform_ds = files_ds.map(get_waveform_and_label)\n",
        "  if noisy_reps_of_known is not None:\n",
        "    # create a few copies of only the target words to balance the distribution\n",
        "    # create a tmp dataset with only the target words\n",
        "    ds_only_cmds = waveform_ds.filter(lambda w,l: tf.reduce_any(l == commands))\n",
        "    for noise_level in noisy_reps_of_known:\n",
        "       waveform_ds = waveform_ds.concatenate(copy_with_noise(ds_only_cmds, rms_level=noise_level))\n",
        "  if num_silent > 0:\n",
        "    silent_wave_ds = create_silence_dataset(num_silent, wave_length_samps,\n",
        "                                            rms_noise_range=[0.01,0.2],\n",
        "                                            silent_label=silence_str)\n",
        "    waveform_ds = waveform_ds.concatenate(silent_wave_ds)\n",
        "  print(f\"Added {num_silent} silent wavs and ?? noisy wavs\")\n",
        "  num_waves = 0\n",
        "  output_ds = wavds2specds(waveform_ds)\n",
        "  return output_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQRyJYGNDWKh",
        "outputId": "f682466e-94a5-48c9-fb8c-83d1c9efc719"
      },
      "outputs": [],
      "source": [
        "print(f\"We have {len(train_files)}/{len(val_files)}/{len(test_files)} training/validation/test files\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APBXoJvmk7FR"
      },
      "source": [
        "Testing preprocessing on a few files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWFwrrTzDX7F",
        "outputId": "6ebad8cf-547e-4491-f386-589fcf910ba1"
      },
      "outputs": [],
      "source": [
        "# print(train_files[:20])\n",
        "print(label_list)\n",
        "train_files[:20]\n",
        "\n",
        "tmp_ds = preprocess_dataset(train_files[:20])\n",
        "print(count_labels(tmp_ds))\n",
        "\n",
        "if tf.test.is_gpu_available():\n",
        "    device_name = '/GPU:0'\n",
        "    print('Running on GPU')\n",
        "else:\n",
        "    device_name = '/CPU:0'\n",
        "    print('Running on CPU')\n",
        "\n",
        "with tf.device(device_name):\n",
        "    tmp_ds = preprocess_dataset(train_files[:20], noisy_reps_of_known=[0.05,0.1])\n",
        "    print(count_labels(tmp_ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0faE-xYjk_y5"
      },
      "source": [
        "Preprocess all files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9egHcQPwDZqS",
        "outputId": "5488f012-6814-4537-8b6d-b15f731ea9a7"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "if tf.test.is_gpu_available():\n",
        "    device_name = '/GPU:0'\n",
        "    print('Running on GPU')\n",
        "else:\n",
        "    device_name = '/CPU:0'\n",
        "    print('Running on CPU')\n",
        "\n",
        "with tf.device(device_name):\n",
        "    train_ds = preprocess_dataset(train_files, noisy_reps_of_known=[0.05,0.1,0.15,0.2,0.25])\n",
        "    val_ds = preprocess_dataset(val_files)\n",
        "    test_ds = preprocess_dataset(test_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssV8LBwqlF1w"
      },
      "source": [
        "Remove whitespace from .txt files and find the number of values in each dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ma_E_piDcD_"
      },
      "outputs": [],
      "source": [
        "def modify_testing_list(file_path):\n",
        "    # Read all lines from the file\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    # Remove the first line\n",
        "    modified_lines = lines[1:]\n",
        "\n",
        "    # Remove leading and trailing whitespace from each line\n",
        "    modified_lines = [line.strip() for line in modified_lines]\n",
        "\n",
        "    # Write the modified lines back to the file\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write('\\n'.join(modified_lines))\n",
        "\n",
        "# Specify the path to testing_list.txt\n",
        "file_path = '/content/drive/My Drive/ML_IOT/dataset/testing_list.txt'\n",
        "\n",
        "# Call the function to modify the file\n",
        "modify_testing_list(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0r6TtPSDeCa",
        "outputId": "b3e7d70e-d0b1-4029-9768-1a1163662492"
      },
      "outputs": [],
      "source": [
        "print(\"training data set\")\n",
        "print(count_labels(train_ds))\n",
        "print(\"val_ds data set\")\n",
        "print(count_labels(val_ds))\n",
        "print(\"test_ds data set\")\n",
        "print(count_labels(test_ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VZU4uXRltNx"
      },
      "source": [
        "Perform batching and ensure the input has the proper shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ooAipp_vDfXy"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.shuffle(int(len(train_files)*1.2))\n",
        "val_ds = val_ds.shuffle(int(len(val_files)*1.2))\n",
        "test_ds = test_ds.shuffle(int(len(test_files)*1.2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "nCrFfU2tDg1x"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "train_ds = train_ds.batch(batch_size)\n",
        "val_ds = val_ds.batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "lzPS39TVDh9O"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.cache().prefetch(AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJDhGYc0DjIC",
        "outputId": "24764792-8cf8-4fa3-d68a-20adaab45875"
      },
      "outputs": [],
      "source": [
        "for spectrogram, _ in train_ds.take(1):\n",
        "  spec1 = spectrogram\n",
        "# take(1) takes 1 *batch*, so we have to select the first\n",
        "# spectrogram from it, hence the [0]\n",
        "print(f\"Spectrogram shape {spec1[0].shape}\")\n",
        "print(f\"ranges from {np.min(spec1)} to {np.max(spec1)}\")   # min/max across the whole batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAaXra1HDkSz",
        "outputId": "08e3f68b-ec2c-47f4-e630-a4c00c527856"
      },
      "outputs": [],
      "source": [
        "for spectrogram, _ in train_ds.take(1):\n",
        "  # take(1) takes 1 *batch*, so we have to select the first\n",
        "  # spectrogram from it, hence the [0]\n",
        "  input_shape = spectrogram[0].shape\n",
        "print('Input shape:', input_shape)\n",
        "num_labels = len(label_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjQmfdP9DltO",
        "outputId": "0f72b89f-3e24-46a3-9375-c0300e3b625d"
      },
      "outputs": [],
      "source": [
        "label_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCN3TGKFDm5W",
        "outputId": "8942e051-f912-479f-9d99-f042e3a93c74"
      },
      "outputs": [],
      "source": [
        "print('Input shape:', input_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irmMcf3dl2Yp"
      },
      "source": [
        "# CNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fgk6P6eDmg-v"
      },
      "source": [
        "Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "5qGKXcBlDoiv"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, DepthwiseConv2D, Dropout, MaxPooling2D, Flatten, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "nXBRqT_DDpsd"
      },
      "outputs": [],
      "source": [
        "def build_model(input_shape, num_labels, l2, lr):\n",
        "    print('Input shape:', input_shape)\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, 3, kernel_regularizer=regularizers.l2(l2)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.MaxPooling2D(name='pool1'),\n",
        "\n",
        "        layers.Conv2D(64, 3, kernel_regularizer=regularizers.l2(l2)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.MaxPooling2D(name='pool2'),\n",
        "\n",
        "        layers.Conv2D(128, 3, kernel_regularizer=regularizers.l2(l2)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.MaxPooling2D(name='pool3'),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, kernel_regularizer=regularizers.l2(l2)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.Dropout(0.5),\n",
        "\n",
        "        layers.Dense(128, kernel_regularizer=regularizers.l2(l2)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.Dropout(0.5),\n",
        "\n",
        "        layers.Dense(num_labels),\n",
        "    ], name=\"modified_simple_cnn\")\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=['accuracy'],\n",
        "    )\n",
        "\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        min_delta=0.01,\n",
        "        patience=4,\n",
        "        verbose=2,\n",
        "        mode='max',\n",
        "        restore_best_weights=True)\n",
        "\n",
        "    return model, early_stopping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmCllcVDD0Pw",
        "outputId": "49e74a5e-f19c-4fae-932c-90eea9c89b27"
      },
      "outputs": [],
      "source": [
        "l2_value=0.0001\n",
        "lr=0.001\n",
        "EPOCHS=50\n",
        "model, early_stopping = build_model(input_shape, num_labels,l2_value, lr)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQse0d2XD1YZ",
        "outputId": "cf626e5b-a48c-4470-b843-d3c454f5487e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, LearningRateScheduler\n",
        "import datetime\n",
        "\n",
        "\n",
        "# Define the callbacks\n",
        "checkpoint_callback = ModelCheckpoint(filepath='model.h5', monitor='val_accuracy', save_best_only=True)\n",
        "tensorboard_callback = TensorBoard(log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), histogram_freq=1)\n",
        "\n",
        "# Train the model with the callbacks\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=10,\n",
        "                    callbacks=[early_stopping, checkpoint_callback, tensorboard_callback])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWtvmq1Wl9xA"
      },
      "source": [
        "Save model as .h5 file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "cmZ3WtoqD2m_",
        "outputId": "d5b67137-80f0-44a3-c0a7-0b8813a23e12"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "model_file_name = \"CNNModelFinished.h5\"\n",
        "print(f\"Saving model to {model_file_name}\")\n",
        "model.save(model_file_name, overwrite=True)\n",
        "\n",
        "# Download the model file\n",
        "files.download(model_file_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "9w9YqMYXD3_V"
      },
      "outputs": [],
      "source": [
        "with open(model_file_name.split('.')[0] + '.txt', 'w') as fpo:\n",
        "    fpo.write(f\"i16min            = {i16min           }\\n\")\n",
        "    fpo.write(f\"i16max            = {i16max           }\\n\")\n",
        "    fpo.write(f\"fsamp             = {fsamp            }\\n\")\n",
        "    fpo.write(f\"wave_length_ms    = {wave_length_ms   }\\n\")\n",
        "    fpo.write(f\"wave_length_samps = {wave_length_samps}\\n\")\n",
        "    fpo.write(f\"window_size_ms    = {window_size_ms   }\\n\")\n",
        "    fpo.write(f\"window_step_ms    = {window_step_ms   }\\n\")\n",
        "    fpo.write(f\"num_filters       = {num_filters      }\\n\")\n",
        "    fpo.write(f\"use_microfrontend = {use_microfrontend}\\n\")\n",
        "    fpo.write(f\"label_list        = {label_list}\\n\")\n",
        "    fpo.write(f\"spectrogram_shape = {spectrogram.numpy().shape}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64W4A6tymEJe"
      },
      "source": [
        "Plot training and validation losses and accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "RsabRLTZD5bL",
        "outputId": "a3925220-3e75-47c1-dd49-6491368d64b6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'history' is the variable that stores the model training history\n",
        "metrics = history.history\n",
        "\n",
        "# Plot the training and validation loss on the top subplot\n",
        "plt.subplot(2,1,1)\n",
        "plt.semilogy(history.epoch, metrics['loss'], metrics['val_loss'])\n",
        "plt.legend(['training', 'validation'])\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "# Plot the training and validation accuracy on the bottom subplot\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(history.epoch, metrics['accuracy'], metrics['val_accuracy'])\n",
        "plt.legend(['training', 'validation'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "# Save the plot as a PNG file\n",
        "# plt.savefig('./figs/loss and acc.png', dpi=300, bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "s5ATrzBjD8Ih"
      },
      "outputs": [],
      "source": [
        "test_audio = []\n",
        "test_labels = []\n",
        "\n",
        "for audio, label in test_ds:\n",
        "  test_audio.append(audio.numpy())\n",
        "  test_labels.append(label.numpy())\n",
        "\n",
        "test_audio = np.array(test_audio)\n",
        "test_labels = np.array(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqnPX92sD9bF",
        "outputId": "bdeb0f5a-722d-43d4-d6b5-7222f1351d56"
      },
      "outputs": [],
      "source": [
        "y_pred = np.argmax(model.predict(test_audio), axis=1)\n",
        "y_true = test_labels\n",
        "\n",
        "test_acc = sum(y_pred == y_true) / len(y_true)\n",
        "print(f'Test set accuracy: {test_acc:.0%}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88vdbLvAmP6h"
      },
      "source": [
        "Plot test set confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "UtXVKG3_EAVi",
        "outputId": "06353ba7-7ccf-4248-f7a1-1b8aa85d35bc"
      },
      "outputs": [],
      "source": [
        "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
        "\n",
        "frr_list = []\n",
        "for i in range(len(label_list)):\n",
        "  tp = confusion_mtx[i][i]\n",
        "  fn = sum(confusion_mtx[i]) - tp\n",
        "  frr = fn / (fn + tp)\n",
        "  frr_list.append(frr)\n",
        "  print(f'{label_list[i]} FRR: {frr:.0%}')\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(confusion_mtx, xticklabels=label_list, yticklabels=label_list,\n",
        "            annot=True, fmt='g')\n",
        "plt.gca().invert_yaxis() # flip so origin is at bottom left\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Label')\n",
        "plt.title(f'Test set conf matrix\\nFRR: {np.mean(frr_list):.0%}')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJzgj_5jmWBA"
      },
      "source": [
        "Plot training set confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "lnLEaoNyEBk7",
        "outputId": "be6627cb-5cfb-400e-b9ca-624db34d5280"
      },
      "outputs": [],
      "source": [
        "dset = train_ds.unbatch()\n",
        "print(\"On training set:\")\n",
        "\n",
        "ds_audio = []\n",
        "ds_labels = []\n",
        "\n",
        "for audio, label in dset:\n",
        "  ds_audio.append(audio.numpy())\n",
        "  ds_labels.append(label.numpy())\n",
        "\n",
        "ds_labels = np.array(ds_labels)\n",
        "ds_audio = np.array(ds_audio)\n",
        "\n",
        "model_out = model.predict(ds_audio)\n",
        "y_pred = np.argmax(model_out, axis=1)\n",
        "y_true = ds_labels\n",
        "\n",
        "ds_acc = sum(y_pred == y_true) / len(y_true)\n",
        "print(f'Data set accuracy: {ds_acc:.0%}')\n",
        "\n",
        "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
        "\n",
        "frr_list = []\n",
        "for i in range(len(label_list)):\n",
        "  tp = confusion_mtx[i][i]\n",
        "  fn = sum(confusion_mtx[i]) - tp\n",
        "  frr = fn / (fn + tp)\n",
        "  frr_list.append(frr)\n",
        "  print(f'{label_list[i]} FRR: {frr:.0%}')\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(confusion_mtx, xticklabels=label_list, yticklabels=label_list,\n",
        "            annot=True, fmt='g')\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Label')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e88YgI5am_ts"
      },
      "source": [
        "Quantize and convert to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mG4sFFtm-x5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load the Keras model from .h5 file\n",
        "model = tf.keras.models.load_model('CNNModelFinished.h5')\n",
        "\n",
        "# Set up TFLite converter\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Disable experimental lowering of tensor list ops\n",
        "converter._experimental_lower_tensor_list_ops = False\n",
        "\n",
        "# Enable Select TensorFlow ops\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "\n",
        "# Set other converter settings as before\n",
        "num_calibration_steps = 10\n",
        "ds_iter = val_ds.unbatch().batch(1).as_numpy_iterator()\n",
        "\n",
        "def representative_dataset_gen():\n",
        "    for _ in range(num_calibration_steps):\n",
        "        next_input = next(ds_iter)[0]\n",
        "        next_input = next_input.astype(np.float32)\n",
        "        yield [next_input]\n",
        "\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "# Convert the model to TensorFlow Lite format\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "# Save the TensorFlow Lite model to a .tflite file\n",
        "tflite_file_name = 'model.tflite'\n",
        "with open(tflite_file_name, \"wb\") as fpo:\n",
        "    num_bytes_written = fpo.write(tflite_quant_model)\n",
        "print(f\"Wrote {num_bytes_written} / {len(tflite_quant_model)} bytes to tflite file\")\n",
        "\n",
        "# Convert the .tflite file to a .cc file\n",
        "!xxd -i {tflite_file_name} > model.cc\n",
        "\n",
        "\n",
        "# Save the TensorFlow Lite model to a .tflite file\n",
        "tflite_file_name = 'model.tflite'\n",
        "with open(tflite_file_name, \"wb\") as fpo:\n",
        "    num_bytes_written = fpo.write(tflite_quant_model)\n",
        "print(f\"Wrote {num_bytes_written} / {len(tflite_quant_model)} bytes to tflite file\")\n",
        "\n",
        "# Convert the .tflite file to a .cc file\n",
        "!xxd -i {tflite_file_name} > model.cc\n",
        "\n",
        "# Download the C++ file\n",
        "from google.colab import files\n",
        "files.download('model.cc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPIt1QkmnG-D"
      },
      "outputs": [],
      "source": [
        "# Download the .tflite file\n",
        "from google.colab import files\n",
        "files.download('model.tflite')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e0T6gFCmmUO"
      },
      "source": [
        "# GRU MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vonCoDu6EFh6"
      },
      "source": [
        "Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "MzNN9gZtEC35"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models, regularizers\n",
        "\n",
        "def lstm_build_model(input_shape, num_labels, l2, lr):\n",
        "    print('Input shape:', input_shape)\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, 3, kernel_regularizer=regularizers.l2(l2)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.MaxPooling2D(name='pool1'),\n",
        "\n",
        "        layers.Conv2D(64, 3, kernel_regularizer=regularizers.l2(l2)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.MaxPooling2D(name='pool2'),\n",
        "\n",
        "        layers.Conv2D(128, 3, kernel_regularizer=regularizers.l2(l2)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.MaxPooling2D(name='pool3'),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, kernel_regularizer=regularizers.l2(l2)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.Dropout(0.5),\n",
        "\n",
        "        layers.Dense(128, kernel_regularizer=regularizers.l2(l2)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.Dropout(0.5),\n",
        "\n",
        "        layers.Reshape((-1, 128)),  # Reshape for LSTM layer\n",
        "        layers.LSTM(128),  # Adjust the number of units to match the Dense layer\n",
        "        layers.Dense(num_labels),\n",
        "    ], name=\"modified_lstm_model\")\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=['accuracy'],\n",
        "    )\n",
        "\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        min_delta=0.01,\n",
        "        patience=4,\n",
        "        verbose=2,\n",
        "        mode='max',\n",
        "        restore_best_weights=True)\n",
        "\n",
        "    return model, early_stopping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zfk-MBFoEJUJ",
        "outputId": "740448c2-6348-416f-e87f-1bff0713a714"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
        "import datetime\n",
        "\n",
        "l2_value=0.0001\n",
        "lr=0.001\n",
        "EPOCHS=50\n",
        "\n",
        "# Create GRU model and early stopping callback\n",
        "model, early_stopping = lstm_build_model(input_shape, num_labels, l2_value, lr)\n",
        "model.summary()\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint_callback = ModelCheckpoint(filepath='gru_model.h5', monitor='val_accuracy', save_best_only=True)\n",
        "tensorboard_callback = TensorBoard(log_dir=\"logs/gru_fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), histogram_freq=1)\n",
        "\n",
        "# Train the GRU model with the callbacks\n",
        "gru_history = model.fit(train_ds, validation_data=val_ds, epochs=10,\n",
        "                    callbacks=[early_stopping, checkpoint_callback, tensorboard_callback])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRgE4EstmuE_"
      },
      "source": [
        "Plot training and validation losses and accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "yHdxiAJ1vrBs",
        "outputId": "4780c20d-4e57-476c-dcb5-6e4eacef9f2f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'history' is the variable that stores the model training history\n",
        "metrics = gru_history.history\n",
        "\n",
        "# Plot the training and validation loss on the top subplot\n",
        "plt.subplot(2,1,1)\n",
        "plt.semilogy(gru_history.epoch, metrics['loss'], metrics['val_loss'])\n",
        "plt.legend(['training', 'validation'])\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "# Plot the training and validation accuracy on the bottom subplot\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(gru_history.epoch, metrics['accuracy'], metrics['val_accuracy'])\n",
        "plt.legend(['training', 'validation'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "# Save the plot as a PNG file\n",
        "# plt.savefig('./figs/loss and acc.png', dpi=300, bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWHzJAMcmxak"
      },
      "source": [
        "Save model as .h5 file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "-CpKkwotEJq-",
        "outputId": "73c0a997-452d-4051-b2f3-cc3389fde9ca"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "model_file_name = \"RNNModelFinished.h5\"\n",
        "print(f\"Saving model to {model_file_name}\")\n",
        "model.save(model_file_name, overwrite=True)\n",
        "\n",
        "# Download the model file\n",
        "files.download(model_file_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D78I2zZEm0wk"
      },
      "source": [
        "Plot test set confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "knpn5e4kELIa"
      },
      "outputs": [],
      "source": [
        "test_audio = []\n",
        "test_labels = []\n",
        "\n",
        "for audio, label in test_ds:\n",
        "  test_audio.append(audio.numpy())\n",
        "  test_labels.append(label.numpy())\n",
        "\n",
        "test_audio = np.array(test_audio)\n",
        "test_labels = np.array(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDFUcBCUELxx",
        "outputId": "8c15309d-7008-4528-e87d-0765d2cdca8f"
      },
      "outputs": [],
      "source": [
        "y_pred = np.argmax(model.predict(test_audio), axis=1)\n",
        "y_true = test_labels\n",
        "\n",
        "test_acc = sum(y_pred == y_true) / len(y_true)\n",
        "print(f'Test set accuracy: {test_acc:.0%}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "khnsvAhuELEJ",
        "outputId": "b59ad2be-a123-4a35-b755-0fd107dbf460"
      },
      "outputs": [],
      "source": [
        "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
        "\n",
        "frr_list = []\n",
        "for i in range(len(label_list)):\n",
        "  tp = confusion_mtx[i][i]\n",
        "  fn = sum(confusion_mtx[i]) - tp\n",
        "  frr = fn / (fn + tp)\n",
        "  frr_list.append(frr)\n",
        "  print(f'{label_list[i]} FRR: {frr:.0%}')\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(confusion_mtx, xticklabels=label_list, yticklabels=label_list,\n",
        "            annot=True, fmt='g')\n",
        "plt.gca().invert_yaxis() # flip so origin is at bottom left\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Label')\n",
        "plt.title(f'Test set conf matrix\\nFRR: {np.mean(frr_list):.0%}')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OMuPZUjm3ou"
      },
      "source": [
        "Plot training set confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "_dmxD6LrEMVq",
        "outputId": "dd9abc8f-2c58-4dbb-8ef0-f06c64ea6566"
      },
      "outputs": [],
      "source": [
        "dset = train_ds.unbatch()\n",
        "print(\"On training set:\")\n",
        "\n",
        "ds_audio = []\n",
        "ds_labels = []\n",
        "\n",
        "for audio, label in dset:\n",
        "  ds_audio.append(audio.numpy())\n",
        "  ds_labels.append(label.numpy())\n",
        "\n",
        "ds_labels = np.array(ds_labels)\n",
        "ds_audio = np.array(ds_audio)\n",
        "\n",
        "model_out = model.predict(ds_audio)\n",
        "y_pred = np.argmax(model_out, axis=1)\n",
        "y_true = ds_labels\n",
        "\n",
        "ds_acc = sum(y_pred == y_true) / len(y_true)\n",
        "print(f'Data set accuracy: {ds_acc:.0%}')\n",
        "\n",
        "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
        "\n",
        "frr_list = []\n",
        "for i in range(len(label_list)):\n",
        "  tp = confusion_mtx[i][i]\n",
        "  fn = sum(confusion_mtx[i]) - tp\n",
        "  frr = fn / (fn + tp)\n",
        "  frr_list.append(frr)\n",
        "  print(f'{label_list[i]} FRR: {frr:.0%}')\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(confusion_mtx, xticklabels=label_list, yticklabels=label_list,\n",
        "            annot=True, fmt='g')\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Label')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzXoDFnVnJef"
      },
      "source": [
        "Quantize and convert to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "jg8fGvd0EXoh",
        "outputId": "06dae8fc-436b-47e3-98fc-9e16c96722ce"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load the Keras model from .h5 file\n",
        "modelGRU = tf.keras.models.load_model('RNNModelFinished.h5')\n",
        "\n",
        "# Set up TFLite converter\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(modelGRU)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Disable experimental lowering of tensor list ops\n",
        "converter._experimental_lower_tensor_list_ops = False\n",
        "\n",
        "# Enable Select TensorFlow ops\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "\n",
        "# Set other converter settings as before\n",
        "num_calibration_steps = 10\n",
        "ds_iter = val_ds.unbatch().batch(1).as_numpy_iterator()\n",
        "\n",
        "def representative_dataset_gen():\n",
        "    for _ in range(num_calibration_steps):\n",
        "        next_input = next(ds_iter)[0]\n",
        "        next_input = next_input.astype(np.float32)\n",
        "        yield [next_input]\n",
        "\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "# Convert the model to TensorFlow Lite format\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "# Save the TensorFlow Lite model to a .tflite file\n",
        "tflite_file_name = 'modelLSTM.tflite'\n",
        "with open(tflite_file_name, \"wb\") as fpo:\n",
        "    num_bytes_written = fpo.write(tflite_quant_model)\n",
        "print(f\"Wrote {num_bytes_written} / {len(tflite_quant_model)} bytes to tflite file\")\n",
        "\n",
        "# Convert the .tflite file to a .cc file\n",
        "!xxd -i {tflite_file_name} > modelGRU.cc\n",
        "\n",
        "\n",
        "# Save the TensorFlow Lite model to a .tflite file\n",
        "tflite_file_name = 'modelLSTM.tflite'\n",
        "with open(tflite_file_name, \"wb\") as fpo:\n",
        "    num_bytes_written = fpo.write(tflite_quant_model)\n",
        "print(f\"Wrote {num_bytes_written} / {len(tflite_quant_model)} bytes to tflite file\")\n",
        "\n",
        "# Convert the .tflite file to a .cc file\n",
        "!xxd -i {tflite_file_name} > modelLSTM.cc\n",
        "\n",
        "# Download the C++ file\n",
        "from google.colab import files\n",
        "files.download('modelLSTM.cc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkvrdMNYT_L8",
        "outputId": "6f9f98af-71b8-4f8f-e003-4775a987e393"
      },
      "outputs": [],
      "source": [
        "# Load the converted TensorFlow Lite model\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output details\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Print input and output details\n",
        "print(\"Input details:\", input_details)\n",
        "print(\"Output details:\", output_details)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "TsXF-DxD4O8G",
        "outputId": "5676e1e4-0c59-46de-c025-92400da3c923"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_02621b76-fe0c-459d-9ace-4ef1d775222c\", \"modelGRU.tflite\", 150968)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Download the .tflite file\n",
        "from google.colab import files\n",
        "files.download('modelGRU.tflite')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
